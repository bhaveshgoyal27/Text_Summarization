{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Legal Document Summarizer__\n",
    "\n",
    "This model is a combination of both extractive and abstractive text summarization approaches.\n",
    "\n",
    "__Extractive__: \n",
    "Extractive, where important sentences are selected from the input text to form a summary. Most summarization approaches today are extractive in nature. It is based on the PageRank algorithm used in Google search Engine.\n",
    "\n",
    "__Abstractive__:\n",
    "Abstractive, where the model forms its own phrases and sentences to offer a more coherent summary, like what a human would generate. This approach is definitely a more appealing, but much more difficult than extractive summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Data Used for Training__\n",
    "\n",
    "Legal Case Reports Data Set contains Australian legal cases from the Federal Court of Australia (FCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Data contained documents with average character length of 15000. Using __TextRank extractive approach__ the text length was reduced to an average of 3000 characters (Composed of top ranking sentences in the Text based on Page Rank Algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Summary Prediction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "clean_text = pd.Series(text1).replace(\"[^a-zA-Z0-9]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1 this is an appeal from a judgment of riethmu...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data for Testing\n",
    "\n",
    "text1 = \"\"\"1 this is an appeal from a judgment of riethmuller fm, given on 17 august 2005, dismissing an application for review of a decision of the refugee review tribunal (\"the tribunal\") to refuse the appellant the grant of a protection visa.\n",
    "8 riethmuller fm then proceeded to consider the appellant's claim that there had been jurisdictional error in that the tribunal had not given him sufficient time to present his case.\n",
    "his honour noted that there was correspondence from the tribunal which put the appellant on notice that the tribunal was not able to make a favourable decision upon the evidence he had provided in support of his application and that he had been given ample opportunity to provide more information.\n",
    "10 the appellant filed a notice of appeal dated 22 august 2005 contending that the adjournment application should not have been refused by riethmuller fm because he was ill on the day of the hearing and he was not given sufficient time to plead his case in detail.\n",
    "subsequently, the appellant filed an outline of submissions dated 19 december 2005 which largely sets out the appellant's factual background and repeats his substantive claims before riethmuller fm, namely that the tribunal failed to take his particular facts and circumstances into account, did not act in good faith and acted unreasonably.\n",
    "in an outline of submissions filed on 2 december 2005, the first respondent submitted that it was open to riethmuller fm to refuse the appellant's application for an adjournment of the hearing in the federal magistrates court for the reasons given by his honour.\n",
    "riethmuller fm was entitled to take the view that the most appropriate order in the interests of justice, bearing in mind the matters relied on by the appellant, the previous history of the proceedings, and the needs of other litigants and the court, was to decline to adjourn the hearing: see szbfl v refugee review tribunal [2005] fca 869 at [8] - [10] ; applicant mzqaf v minister for immigration and multicultural and indigenous affairs [2005] fca 1801 at [5] ; and nalm v minister for immigration and multicultural and indigenous affairs [2004] fcafc 17 at [22] - [26] .\n",
    "13 as his honour pointed out, the tribunal was required to determine whether the appellant had a well-founded fear of persecution for a convention reason, based upon the appellant's particular claims.\n",
    "the appellant did not proffer any explanation as to why the material in question had not been presented to the tribunal or at the hearing before riethmuller fm, other than to say it was not yet available to him.\n",
    "15 in my opinion, the notice of appeal and the appellant's submissions, both written and oral, do not disclose any error of fact or law in the decision of riethmuller fm, or for that matter in the decision of the tribunal.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "summ1 = \"\"\"appeal from decision of federal magistrate.\n",
    "protection visa.\n",
    "procedural unfairness.\n",
    "whether appellant had sufficient time to plead case.\n",
    "or obtain additional country information.\n",
    "no error established.\n",
    "migration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_text = [text1]\n",
    "l_summ = [summ1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 august 2005 (DATE)\n",
      "august 2005 (DATE)\n",
      "the day (DATE)\n",
      "19 december 2005 (DATE)\n",
      "2 december 2005 (DATE)\n",
      "first (ORDINAL)\n",
      "2005 (DATE)\n",
      "2005 (DATE)\n",
      "2004 (DATE)\n"
     ]
    }
   ],
   "source": [
    "# Entity Recognition\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load the large English NLP model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# The text we want to examine\n",
    "text = text1\n",
    "\n",
    "# Parse the text with spaCy. This runs the entire pipeline.\n",
    "doc = nlp(text)\n",
    "\n",
    "# 'doc' now contains a parsed version of text. We can use it to do anything we want!\n",
    "# For example, this will print out all the named entities that were detected:\n",
    "for entity in doc.ents:\n",
    "    if entity.label_!=\"CARDINAL\":\n",
    "        print(f\"{entity.text} ({entity.label_})\")# if entity.label_!=\"CARDINAL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visa\n",
      "protection\n",
      "riethmuller\n",
      "fm\n",
      "honour\n",
      "v\n",
      "facts\n",
      "fact\n",
      "substantive claims\n",
      "claim\n"
     ]
    }
   ],
   "source": [
    "# Keywords found in text\n",
    "\n",
    "from summa import keywords\n",
    "print(keywords.keywords(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pickle file ...\n",
      "max_input_seq_length 500\n",
      "max_target_seq_length 50\n",
      "num_input_tokens 5002\n",
      "num_target_tokens 1391\n",
      "start predicting ...\n",
      "--Generated Summary:  application for another magistrate.\n",
      "protection visa.\n",
      "procedural unfairness.\n",
      "whether from from had error and plead error in applicant's had error in plead error in information.\n",
      "no error in information.\n",
      "no error in information.\n",
      "no error in information.\n",
      "no error in applicant's had information.\n",
      "no error in applicant's had information.\n",
      "no error in applicant's had information.\n",
      "no error in applicant's\n",
      "--Original Summary:  appeal from decision of federal magistrate.\n",
      "protection visa.\n",
      "procedural unfairness.\n",
      "whether appellant had sufficient time to plead case.\n",
      "or obtain additional country information.\n",
      "no error established.\n",
      "migration.\n",
      "\n",
      "Rouge Score:\n",
      "[{'rouge-1': {'f': 0.5333333285333334, 'p': 0.4444444444444444, 'r': 0.6666666666666666}, 'rouge-2': {'f': 0.285714280733028, 'p': 0.2692307692307692, 'r': 0.30434782608695654}, 'rouge-l': {'f': 0.4952380952374046, 'p': 0.4444444444444444, 'r': 0.6666666666666666}}]\n"
     ]
    }
   ],
   "source": [
    "## Predicting Summary\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "from keras_text_summarization.library.rnn import RecursiveRNN1\n",
    "from rouge import Rouge \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    data_dir_path = './data'\n",
    "    model_dir_path = './models'\n",
    "\n",
    "    print('loading pickle file ...')\n",
    "    \n",
    "    with open(data_dir_path + '/summary2.pkl', 'rb') as f:\n",
    "        list_of_summaries = pickle.load(f)\n",
    "    with open(data_dir_path + '/text2.pkl', 'rb') as f:\n",
    "        list_of_text = pickle.load(f)\n",
    "    \n",
    "#     X = list_of_text[0:10]\n",
    "#     Y = list_of_summaries[0:10]\n",
    "    \n",
    "    X = l_text\n",
    "    Y = l_summ\n",
    "\n",
    "    config = np.load(RecursiveRNN1.get_config_file_path(model_dir_path=model_dir_path)).item()\n",
    "\n",
    "    summarizer = RecursiveRNN1(config)\n",
    "    summarizer.load_weights(weight_file_path=RecursiveRNN1.get_weight_file_path(model_dir_path=model_dir_path))\n",
    "\n",
    "    print('start predicting ...')\n",
    "    orig_summary = []\n",
    "    generated_summary = []\n",
    "    for i in np.random.permutation(np.arange(len(X)))[0:20]:\n",
    "        x = X[i]\n",
    "        actual_summary = Y[i]\n",
    "        orig_summary.append(actual_summary)\n",
    "        \n",
    "        gen_summary = summarizer.summarize(x)\n",
    "        generated_summary.append(gen_summary)\n",
    "        \n",
    "        # print('Article: ', x)\n",
    "        print('--Generated Summary: ', gen_summary)\n",
    "        print('--Original Summary: ', actual_summary)\n",
    "    \n",
    "#     with open('gen_summary1.pkl', 'wb') as f:\n",
    "#         pickle.dump(generated_summary, f)\n",
    "#     with open('orig_summary1.pkl', 'wb') as f:\n",
    "#         pickle.dump(orig_summary, f)\n",
    "\n",
    "\n",
    "    hypothesis = actual_summary\n",
    "    reference = gen_summary\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "    print('\\n' + 'Rouge Score:')\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
